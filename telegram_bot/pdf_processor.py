import subprocess
from langchain_ollama import OllamaLLM
from pathlib import Path
import pdfplumber
import re
import logging
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, HRFlowable, Flowable
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.units import cm
from reportlab.lib import colors
import os
from emojipy import Emoji
import yaml
from reference_data import types_info, hidden_talents_info, personality_info, orientations

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è pdfminer
logging.getLogger("pdfminer").setLevel(logging.ERROR)
ollama = OllamaLLM(base_url="http://llm_service:11434", model="yandex/YandexGPT-5-Lite-8B-instruct-GGUF:latest")

# –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

def extract_text_from_pdf(path):
    text = ""
    with pdfplumber.open(path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

def clean_text(text):
    # –£–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –≤–∏–¥–∞:
    # "https://bot.youcan.by/admin/info/user/<—á–∏—Å–ª–æ>/" —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –Ω–æ–º–µ—Ä–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–∏–ø–∞ "18/20"
    text = re.sub(
        r"(https?://)?bot\.youcan\.by/admin/info/user/\d+/\s*\d+/\d+",
        "",
        text
    )
    # –£–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –≤–∏–¥–∞ "https://bot.youcan.by/admin/info/user/<—á–∏—Å–ª–æ>/"
    text = re.sub(
        r"(https?://)?bot\.youcan\.by/admin/info/user/\d+/",
        "",
        text
    )
    # –£–¥–∞–ª—è–µ–º –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ "23 —Å–µ–Ω—Ç—è–±—Ä—è 2024 –≥. 12:02", "23.09.2024, 12:58" –∏ "2024-09-23 12:03:45"
#    text = re.sub(r"\d{1,2} (?:—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è) \d{4} –≥?\.? \d{1,2}:\d{2}", "", text)
    text = re.sub(r"\d{1,2}\.\d{1,2}\.\d{4},? \d{1,2}:\d{2}", "", text)
    text = re.sub(r"\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}", "", text)
    # –£–¥–∞–ª—è–µ–º –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ —Ñ–æ—Ä–º–∞—Ç–µ "18/20"
    text = re.sub(r"\d+/\d+", "", text)
    # –£–¥–∞–ª—è–µ–º —Ñ—Ä–∞–∑—É "–¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω:"
#    text = re.sub(r"–¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω:\s*", "", text)
    return text.strip()

def parse_user_info(text):
    lines = text.strip().splitlines()
    name_pattern = re.compile(r"^[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)+$")
    for line in lines[:10]:
        candidate = line.strip()
        if name_pattern.match(candidate):
            return candidate
    return lines[0].strip() if lines else ""

def get_task_body(task_text):
    """
    –ò–∑ –±–ª–æ–∫–∞ –∑–∞–¥–∞–Ω–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–µ–π "–¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω:"
    (—Ç–æ –µ—Å—Ç—å –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º).
    """
    pattern = re.compile(r"–¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω:\s*\n.*?\n(.*)", re.DOTALL)
    m = pattern.search(task_text)
    if m:
        return m.group(1).strip()
    else:
        return task_text.strip()

def extract_task(text, task_number):
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–ª–æ–∫ –æ—Ç "–ó–∞–¥–∞–Ω–∏–µ ‚Ññ<task_number>" –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ "–ó–∞–¥–∞–Ω–∏–µ ‚Ññ" –∏–ª–∏ –∫–æ–Ω—Ü–∞ —Ç–µ–∫—Å—Ç–∞,
    # –∑–∞—Ç–µ–º –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ —Å "–¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω:".
    pattern = re.compile(rf"(–ó–∞–¥–∞–Ω–∏–µ\s*‚Ññ{task_number}\..*?)(?=–ó–∞–¥–∞–Ω–∏–µ\s*‚Ññ\d+|$)", re.DOTALL)
    match = pattern.search(text)
    if match:
        task_block = match.group(1)
        return get_task_body(task_block)
    else:
        return ""

def parse_task1(task_text):
    pattern = re.compile(r"(\d+)\.\s*(.+?)\s*üí°.*?–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–ª–ª–æ–≤:\s*(\d+)", re.DOTALL)
    results = pattern.findall(task_text)
    parsed = []
    header = "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç–∏"
    for num, description, points in results:
        normalized = " ".join(description.split()).lower()
        if normalized == header:
            continue
        parsed.append({
            "–ø—É–Ω–∫—Ç": int(num),
            "–æ–ø–∏—Å–∞–Ω–∏–µ": description.strip(),
            "–±–∞–ª–ª—ã": int(points)
        })
    # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö —Å–ª–æ–≤–∞—Ä—è –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
    for item in parsed:
        item['–æ–ø–∏—Å–∞–Ω–∏–µ'] = item['–æ–ø–∏—Å–∞–Ω–∏–µ'].replace('\n', ' ').replace('\r', '')
    return parsed


def parse_task2(task_text):
    pattern = re.compile(r"(.+\(\w+\))", re.DOTALL)
    m = pattern.search(task_text)
    result = m.group(1).strip() if m else ""
    # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
    return result.replace('\n', '<br/>').replace('\r', '')


def parse_task2(task_text):
    pattern = re.compile(r"(.+\(\w+\))", re.DOTALL)
    m = pattern.search(task_text)
    result = m.group(1).strip() if m else ""
    # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
    return task_text.replace('\n', '<br/>').replace('\r', '')

def parse_task3(task_text):
    pattern = re.compile(r"(\d+)\.\s*(.+?)\s*üí°.*?–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–ª–ª–æ–≤:\s*(\d+)", re.DOTALL)
    results = pattern.findall(task_text)
    parsed = []
    header = "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏"
    for num, description, points in results:
        normalized = " ".join(description.split()).lower()
        if normalized == header:
            continue
        parsed.append({
            "–ø—É–Ω–∫—Ç": int(num),
            "–æ–ø–∏—Å–∞–Ω–∏–µ": description.strip(),
            "–±–∞–ª–ª—ã": int(points)
        })
    # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö —Å–ª–æ–≤–∞—Ä—è –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
    for item in parsed:
        if isinstance(item['–æ–ø–∏—Å–∞–Ω–∏–µ'], str):
            item['–æ–ø–∏—Å–∞–Ω–∏–µ'] = item['–æ–ø–∏—Å–∞–Ω–∏–µ'].replace('\n', ' ').replace('\r', '')
    return parsed

def parse_task4(task_text):
    pattern = re.compile(
        r"(\d+)\.\s*(.+?)(?=\s+[–ê-–Ø–Å])(?:.*?–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–ª–ª–æ–≤:\s*(\d+))",
        re.DOTALL
    )
    header = "—Ü–µ–Ω–Ω–æ—Å—Ç–Ω—ã–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã"
    results = pattern.findall(task_text)
    parsed = [
        {
            "–æ–ø–∏—Å–∞–Ω–∏–µ": " ".join(description.split()),
            "–±–∞–ª–ª—ã": int(points)
        }
        for num, description, points in results
        if " ".join(description.split()).lower() != header
    ]
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –±–∞–ª–ª–æ–≤ (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
    return sorted(parsed, key=lambda x: x["–±–∞–ª–ª—ã"], reverse=True)


def parse_task5(task_text):
    pattern = re.compile(r"–û—Ç–≤–µ—Ç\s*(.*?)\s*(?=(–ó–∞–¥–∞–Ω–∏–µ\s*‚Ññ|–í–æ–ø—Ä–æ—Å\s*‚Ññ|$))", re.DOTALL)
    match = pattern.search(task_text)
    result = match.group(1).strip() if match else ""
    # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
    return result.replace('\n', ' ').replace('\r', '')

def parse_task6(task_text):
    pattern = re.compile(r'–û—Ç–≤–µ—Ç\s*(.*?)\s*(?=(–í–æ–ø—Ä–æ—Å\s*‚Ññ\d+|$))', re.DOTALL)
    matches = pattern.findall(task_text)
    # –û—á–∏—â–∞–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ—Ç–≤–µ—Ç–æ–≤
    return [match[0].replace('\n', ' ').replace('\r', '') for match in matches]

def parse_task7(task_text):
    pattern = re.compile(r"–û—Ç–≤–µ—Ç\s*(.*?)\s*(?=(–ó–∞–¥–∞–Ω–∏–µ\s*‚Ññ|–í–æ–ø—Ä–æ—Å\s*‚Ññ|$))", re.DOTALL)
    match = pattern.search(task_text)
    result = match.group(1).strip() if match else ""
    # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º

    return result.replace('\n', '<br/>').replace('\r', '<br/>')

def parse_task8(task_text):
    date_pattern = re.compile(r"\d{1,2}\.\d{1,2}\.\d{4},\s*\d{1,2}:\d{2}")
    date_match = date_pattern.search(task_text)
    if date_match:
        start_index = date_match.end()
        remaining_text = task_text[start_index:]
    else:
        remaining_text = task_text

    lines = remaining_text.splitlines()
    filtered_lines = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if re.search(r"(https?://|www\.)", line) or re.search(r"\d+/\d+", line):
            continue
        words = line.split()
        if 1 <= len(words) <= 2 and all(re.fullmatch(r"[–ê-–Ø–Å–∞-—è—ë]+", word) for word in words):
            filtered_lines.append(line)
    return filtered_lines

def replace_with_emoji_pdf(text, size):
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —ç–º–æ–¥–∑–∏ –≤ HTML-—Ç–µ–≥–∏ <img>
    text = Emoji.to_image(text)
    # –ó–∞–¥–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã: —É–∫–∞–∑—ã–≤–∞–µ–º —è–≤–Ω–æ –º–∞–ª–µ–Ω—å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (size –≤ –ø–∏–∫—Å–µ–ª—è—Ö)
    text = re.sub(r'class="[^"]*"', '', text)  # —É–¥–∞–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç class
    text = re.sub(r'style="[^"]*"', '', text)   # —É–¥–∞–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç style
    text = re.sub(r'alt="[^"]*"', '', text)       # —É–¥–∞–ª—è–µ–º alt
    # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã width –∏ height —Å –Ω—É–∂–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏:
    # –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å size –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω—É–∂–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 14)
    text = re.sub(r'<img', f'<img height="{size}" width="{size}"', text)
    return text


 ###########################################################   

def process_pdf(input_pdf_path: str, custom_prof_resume=None, custom_talents_resume=None, custom_final_resume=None) -> str:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω–æ–π PDF, –≤—ã–∑—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Ollama,
    –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π PDF (–Ω–∞–ø—Ä–∏–º–µ—Ä, dossier.pdf) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –Ω–µ–º—É.
    """
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF
    text = extract_text_from_pdf(input_pdf_path)
    text = clean_text(text)
    user_name = parse_user_info(text)

    tasks = {}
    for i in range(1, 9):
        task_text = extract_task(text, i)
        tasks[f"–ó–∞–¥–∞–Ω–∏–µ ‚Ññ{i}"] = task_text.strip()

    # –ó–∞–¥–∞–Ω–∏–µ ‚Ññ1-8
    task1_parsed = parse_task1(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ1", ""))
    task2_parsed = parse_task2(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ2", ""))
    task3_parsed = parse_task3(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ3", ""))
    task4_parsed = parse_task4(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ4", ""))
    task5_parsed = parse_task5(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ5", ""))
    task6_parsed = parse_task6(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ6", ""))
    task7_parsed = parse_task7(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ7", ""))
    task8_parsed = parse_task8(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ8", ""))

    # –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç–∏
    # –ü—Ä–∞–≤–∏–ª–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è (–ø–æ–∏—Å–∫ –ø–æ–¥—Å—Ç—Ä–æ–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏)
    mappings = [
        ({"task1": "—Ä–∞–±–æ—Ç–µ —Å –ª—é–¥—å–º–∏", "task3": "—Å–æ—Ü–∏–∞–ª—å–Ω—ã–π"}, "–°–æ—Ü–∏–∞–ª—å–Ω—ã–π"),
        ({"task1": "—ç—Å—Ç–µ—Ç–∏—á–µ—Å–∫", "task3": "–∞—Ä—Ç–∏—Å—Ç–∏—á–Ω—ã–π"}, "–ê—Ä—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π"),
        ({"task1": "—Ä–∞–±–æ—Ç—ã —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π", "task3": "–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π"}, "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π"),
        ({"task1": "–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π", "task3": "–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π"}, "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π"),
        ({"task1": "—ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω"}, "–≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π"),
        ({"task1": "–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π", "task3": "–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π"}, "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π"),
        ({"task3": "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–Ω—ã–π"}, "–ò–Ω–∏—Ü–∏–∞—Ç–∏–≤–Ω—ã–π")
    ]

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ (–±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
    def match(description, substr):
        return substr.lower() in description.lower()

    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞–ª–ª–æ–≤ –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–∏–ø—É
    scores = {}

    # –†–∞—Å—á–µ—Ç –±–∞–ª–ª–æ–≤ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º
    for rule, type_name in mappings:
        total = 0
        # –ï—Å–ª–∏ –ø—Ä–∞–≤–∏–ª–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±–∞ —É—Å–ª–æ–≤–∏—è: task1 –∏ task3
        if "task1" in rule and "task3" in rule:
            for t1 in task1_parsed:
                if match(t1["–æ–ø–∏—Å–∞–Ω–∏–µ"], rule["task1"]):
                    for t3 in task3_parsed:
                        if match(t3["–æ–ø–∏—Å–∞–Ω–∏–µ"], rule["task3"]):
                            total += t1["–±–∞–ª–ª—ã"] + t3["–±–∞–ª–ª—ã"]
        # –ï—Å–ª–∏ –ø—Ä–∞–≤–∏–ª–æ –∑–∞–¥–∞–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è task1
        elif "task1" in rule:
            for t1 in task1_parsed:
                if match(t1["–æ–ø–∏—Å–∞–Ω–∏–µ"], rule["task1"]):
                    total += t1["–±–∞–ª–ª—ã"]
        # –ï—Å–ª–∏ –ø—Ä–∞–≤–∏–ª–æ –∑–∞–¥–∞–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è task3
        elif "task3" in rule:
            for t3 in task3_parsed:
                if match(t3["–æ–ø–∏—Å–∞–Ω–∏–µ"], rule["task3"]):
                    total += t3["–±–∞–ª–ª—ã"]
        if total > 0:
            scores[type_name] = scores.get(type_name, 0) + total

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ç–∏–ø–æ–≤ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –±–∞–ª–ª–æ–≤
    sorted_types = sorted(scores.items(), key=lambda x: x[1], reverse=True)

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∫–∏ —Å –±–∞–ª–ª–∞–º–∏
    def format_score(score):
        if 11 <= score % 100 <= 19:
            return f"{score} –±–∞–ª–ª–æ–≤"
        else:
            last_digit = score % 10
            if last_digit == 1:
                return f"{score} –±–∞–ª–ª"
            elif last_digit in [2, 3, 4]:
                return f"{score} –±–∞–ª–ª–∞"
            else:
                return f"{score} –±–∞–ª–ª–æ–≤"

    # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–æ—Ñ–∏–ª—è —Å –µ–¥–∏–Ω—ã–º –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ–º –∏ emoji
    aggregated_text_prof = ""
    for type_name, score in sorted_types:
        aggregated_text_prof += f"<br/>üëâ <b>{type_name} —Ç–∏–ø –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:</b><br/>"
        if type_name in types_info:
            info = types_info[type_name]
            aggregated_text_prof += f"üìù {info['description']}<br/>"
            aggregated_text_prof += "üíº –ü–æ–¥—Ö–æ–¥—è—â–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏:<br/>"
            for prof in info["professions"]:
                aggregated_text_prof += f"   ‚úîÔ∏è {prof}<br/>"

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ prompt –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∑—é–º–µ –ø–æ —Ä–∞–∑–¥–µ–ª—É "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç–∏".
    prompts = load_prompts()
    if custom_prof_resume is not None:
        prof_resume = custom_prof_resume
    else:
        prompt_prof = prompts['prof_resume']['template'].format(
            user_name=user_name,
            aggregated_text_prof=aggregated_text_prof
        )
    prof_resume = ollama.invoke(prompt_prof)

    # –õ–∏—á–Ω–æ—Å—Ç–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–¥–∞ –ª–∏—á–Ω–æ—Å—Ç–∏ –∏–∑ —Å—Ç—Ä–æ–∫–∏ (–Ω–∞—Ö–æ–¥–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Å–∫–æ–±–∫–∞—Ö)
    def extract_personality(code_str):
        start = code_str.find("(")
        end = code_str.find(")")
        if start != -1 and end != -1:
            return code_str[start+1:end].strip()
        return None

    personality_code = extract_personality(task2_parsed)

    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–∏–ø—É –ª–∏—á–Ω–æ—Å—Ç–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–∏—Å–∫–∞
    aggregated_text_personality = ""
    if personality_code and personality_code in personality_info:
        info = personality_info[personality_code]
        aggregated_text_personality += f"<br/><br/>üé≠ –¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏: {info['name']}<br/>"
        aggregated_text_personality += f"üìù {info['description']}<br/><br/>"
        aggregated_text_personality += "üöÄ –î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º, —á—Ç–æ –¥–µ–ª–∞–µ—Ç —Ç–µ–±—è —Ç–∞–∫–∏–º –æ—Å–æ–±–µ–Ω–Ω—ã–º:<br/><br/>"
        for feature in info["features"]:
            aggregated_text_personality += f"üîë {feature['feature']}:<br/>"
            aggregated_text_personality += f"üìù {feature['description']}<br/>"
            aggregated_text_personality += f"üí° {feature['examples']}<br/><br/>"
    else:
        aggregated_text_personality = task2_parsed

    # –¶–µ–Ω–Ω–æ—Å—Ç–Ω—ã–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∫–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ü–µ–Ω–Ω–æ—Å—Ç–Ω—ã—Ö –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤
    def build_orientations_text(task_results, orientations):
        aggregated_text_orientations = "–¢–≤–æ–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–Ω—ã–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã –ø–æ–º–æ–≥–∞—é—Ç —Ç–µ–±–µ –ø–æ–Ω—è—Ç—å, —á—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è —Ç–µ–±—è –≤ –∂–∏–∑–Ω–∏ –∏ –∫–∞—Ä—å–µ—Ä–µ. –†–µ–∞–ª–∏–∑—É—è –∏—Ö, —Ç—ã –º–æ–∂–µ—à—å —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å —Å–µ–±—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É—Å–ø–µ—à–Ω—ã–º –∏ –≥–∞—Ä–º–æ–Ω–∏—á–Ω—ã–º –≤ —Å–≤–æ–µ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏. <br/> –î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º, —á—Ç–æ –∑–Ω–∞—á–∏—Ç –∫–∞–∂–¥–∞—è –∏–∑ –Ω–∏—Ö –∏ –∫–∞–∫ –æ–Ω–∏ –º–æ–≥—É—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å—Å—è:"
        for result in task_results:
            desc = result['–æ–ø–∏—Å–∞–Ω–∏–µ']
            data = orientations.get(desc)
            if data:
                aggregated_text_orientations += (
                    f"<br/>üí°{data['–æ—Ä–∏–µ–Ω—Ç–∏—Ä']}<br/>"
                    f"üìù{data['–æ–ø–∏—Å–∞–Ω–∏–µ']}<br/>"
                    "‚úîÔ∏è –ö–∞–∫–æ–π –ø—É—Ç—å —Ç–µ–±–µ –ø–æ–¥–æ–π–¥–µ—Ç?<br/>"
                    f"{data['–ø—É—Ç—å']}<br/>"
                )
            else:
                aggregated_text_orientations += f"<br/><br/>‚ùó –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è: {desc}<br/>"
        return aggregated_text_orientations


    # –ü–æ–ª—É—á–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Ü–µ–Ω–Ω–æ—Å—Ç–Ω—ã—Ö –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤
    aggregated_text_orientations = build_orientations_text(task4_parsed, orientations)

    # –°–∫—Ä—ã—Ç—ã–µ —Ç–∞–ª–∞–Ω—Ç—ã
    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–∞–ª–∞–Ω—Ç—É –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    aggregated_text_talents = ""
    for talent in task8_parsed:
        info = hidden_talents_info.get(talent)
        if info:
            aggregated_text_talents += f"<br/>‚ú® {talent}:<br/>"
            aggregated_text_talents += f"üìù {info['description']}<br/><br/>"
            aggregated_text_talents += "üí° –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:<br/>"
            aggregated_text_talents += f"{info['examples']}<br/>"
        else:
            aggregated_text_talents += f"<br/><br/>‚ùó –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–∞–ª–∞–Ω—Ç—É ¬´{talent}¬ª –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.<br/><br/>"

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ prompt –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∑—é–º–µ –ø–æ —Ä–∞–∑–¥–µ–ª—É "–°–∫—Ä—ã—Ç—ã–µ —Ç–∞–ª–∞–Ω—Ç—ã".
    if custom_talents_resume is not None:
        talents_resume = custom_talents_resume
    else:
        prompt_talents = prompts['talents_resume']['template'].format(
            user_name=user_name,
            aggregated_text_talents=aggregated_text_talents
        )
    talents_resume = ollama.invoke(prompt_talents)

    # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
    if custom_final_resume is not None:
        resume = custom_final_resume
    else:
        prompt_final = prompts['final_resume']['template'].format(
            user_name=user_name,
            aggregated_text_prof=aggregated_text_prof,
            prof_resume=prof_resume,
            aggregated_text_personality=aggregated_text_personality,
            aggregated_text_orientations=aggregated_text_orientations,
            aggregated_text_talents=aggregated_text_talents,
            talents_resume=talents_resume
        )
    resume = ollama.invoke(prompt_final)

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ PDF
    # –ü—É—Ç—å –∫ —à—Ä–∏—Ñ—Ç—É Symbola
    mulish_regular_path = 'Mulish-Regular.ttf'
    if not os.path.exists(mulish_regular_path):
        raise FileNotFoundError(f"–§–∞–π–ª —à—Ä–∏—Ñ—Ç–∞ '{mulish_regular_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    # –ü—É—Ç—å –∫ —à—Ä–∏—Ñ—Ç—É M PLUS Rounded 1c Bold
    mplus_bold_path = 'MPLUSRounded1c-ExtraBold.ttf'
    if not os.path.exists(mplus_bold_path):
        raise FileNotFoundError(f"–§–∞–π–ª —à—Ä–∏—Ñ—Ç–∞ '{rounded_b_font_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —à—Ä–∏—Ñ—Ç–æ–≤
    pdfmetrics.registerFont(TTFont('Mulish-Regular', mulish_regular_path))
    pdfmetrics.registerFont(TTFont('MPlusRounded1cB', mplus_bold_path))

    # –ò–º—è PDF-—Ñ–∞–π–ª–∞
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ "downloads" –≤ —Ç–µ–∫—É—â–µ–π —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    downloads_dir = Path.cwd() / "downloads"
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É PDF-—Ñ–∞–π–ª—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤ –∏–º–µ–Ω–∏
    output_pdf_path = str(downloads_dir / f"–î–æ—Å—å–µ {user_name}.pdf")

    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Ä—Ö–Ω–∏–π –æ—Ç—Å—Ç—É–ø –Ω–∞ –≤—ã—Å–æ—Ç—É header (3 —Å–º) + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä, 40
    doc = SimpleDocTemplate(output_pdf_path,
                            pagesize=A4,
                            rightMargin=40,
                            leftMargin=40,
                            topMargin=3*cm + 40,
                            bottomMargin=40)


    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª–µ–π
    styles = getSampleStyleSheet()
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
    styles['Normal'].fontName = 'Mulish-Regular'
    styles['Normal'].fontSize = 14
    styles['Normal'].leading = 16

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –±–ª–æ–∫–æ–≤
    styles['Heading2'].fontName = "MPlusRounded1cB"
    styles['Heading2'].fontSize = 16
    styles['Heading2'].leading = 20

    # –°—Ç–∏–ª—å –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ ‚Äì –∏—Å–ø–æ–ª—å–∑—É–µ–º –∂–∏—Ä–Ω—ã–π —à—Ä–∏—Ñ—Ç
    title_style = ParagraphStyle(
        'Title',
        parent=styles['Heading2'],
        fontSize=28,
        alignment=1,  # –ø–æ —Ü–µ–Ω—Ç—Ä—É
        spaceAfter=16,
    )

    # –°—Ç–∏–ª—å –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π –±–ª–æ–∫–æ–≤
    block_header_style = ParagraphStyle(
        'BlockHeader',
        parent=styles['Heading2'],
        fontSize=18,
        spaceAfter=8,
    )

    normal_style = styles['Normal']

    # –ö–ª–∞—Å—Å –¥–ª—è –æ–±–æ—Ä–∞—á–∏–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø—É–Ω–∫—Ç–∏—Ä–Ω–æ–π —Ä–∞–º–∫–æ–π –∏ –∑–∞–∫—Ä—É–≥–ª—ë–Ω–Ω—ã–º–∏ —É–≥–ª–∞–º–∏
    class RoundedBorderedParagraph(Flowable):
        def __init__(self, text, style, padding=0.5*cm, radius=10, dash=(3, 3)):
            Flowable.__init__(self)
            self.text = text
            self.style = style
            self.padding = padding
            self.radius = radius
            self.dash = dash
            self.paragraph = Paragraph(text, style)
            self.width = 0
            self.height = 0

        def wrap(self, availWidth, availHeight):
            # –î–æ—Å—Ç—É–ø–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ ‚Äì —Å —É—á—ë—Ç–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤
            available_text_width = availWidth - 2 * self.padding
            w, h = self.paragraph.wrap(available_text_width, availHeight - 2 * self.padding)
            self.width = w + 2 * self.padding
            self.height = h + 2 * self.padding
            return self.width, self.height

        def draw(self):
            # –†–∏—Å—É–µ–º –ø—É–Ω–∫—Ç–∏—Ä–Ω—É—é —Ä–∞–º–∫—É —Å –∑–∞–∫—Ä—É–≥–ª—ë–Ω–Ω—ã–º–∏ —É–≥–ª–∞–º–∏
            self.canv.saveState()
            self.canv.setStrokeColor(colors.HexColor('#f8bb42'))
            self.canv.setLineWidth(1)
            self.canv.setDash(self.dash[0], self.dash[1])
            self.canv.roundRect(0, 0, self.width, self.height, self.radius, stroke=1, fill=0)
            self.canv.restoreState()
            # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç —Å –æ—Ç—Å—Ç—É–ø–æ–º (padding)
            self.paragraph.drawOn(self.canv, self.padding, self.padding)

        def split(self, availWidth, availHeight):
            """
            –ï—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è, —Ä–∞–∑–±–∏–≤–∞–µ–º Paragraph –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π.
            –ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ ‚Äì –Ω–æ–≤—ã–π RoundedBorderedParagraph, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è —Ç–µ–∫—É—â–µ–π –æ–±–ª–∞—Å—Ç–∏.
            """
            available_text_width = availWidth - 2 * self.padding
            available_text_height = availHeight - 2 * self.padding
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ split —É Paragraph
            split_paragraphs = self.paragraph.split(available_text_width, available_text_height)
            if not split_paragraphs:
                return []
            flowables = []
            for p in split_paragraphs:
                new_flowable = RoundedBorderedParagraph("", self.style, self.padding, self.radius, self.dash)
                new_flowable.paragraph = p
                w, h = p.wrap(available_text_width, available_text_height)
                new_flowable.width = w + 2 * self.padding
                new_flowable.height = h + 2 * self.padding
                flowables.append(new_flowable)
            return flowables

    # –ö–∞—Å—Ç–æ–º–Ω—ã–π Flowable –¥–ª—è –ø—É–Ω–∫—Ç–∏—Ä–Ω–æ–π –ª–∏–Ω–∏–∏ –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –±–ª–æ–∫–æ–≤
    class DashedHRFlowable(Flowable):
        def __init__(self, width, thickness=1):
            Flowable.__init__(self)
            self.width = width
            self.thickness = thickness

        def wrap(self, availWidth, availHeight):
            return self.width, self.thickness

        def draw(self):
            self.canv.saveState()
            self.canv.setStrokeColor(colors.HexColor('#f8bb42'))
            self.canv.setLineWidth(self.thickness)
            self.canv.setDash(3, 3)  # 3 –ø—É–Ω–∫—Ç–∞ –ª–∏–Ω–∏—è, 3 –ø—É–Ω–∫—Ç–∞ –ø—Ä–æ–±–µ–ª
            self.canv.line(0, self.thickness/2.0, self.width, self.thickness/2.0)
            self.canv.restoreState()

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –±–ª–æ–∫–∞ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º, –ª–∏–Ω–∏–µ–π –∏ —Ç–µ–∫—Å—Ç–æ–º —Å —Ä–∞–º–∫–æ–π
    def add_block(title, text_content, story):
        story.append(Paragraph(title, block_header_style))
        story.append(Spacer(1, 14))
        bordered_paragraph = RoundedBorderedParagraph(text_content, normal_style)
        story.append(bordered_paragraph)
        story.append(Spacer(1, 24))

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤–µ—Ä—Ö–Ω–µ–≥–æ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–∞ –Ω–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    def header(canvas, doc):
        width, height = A4
        header_height = 3 * cm
        canvas.saveState()
        # –†–∏—Å—É–µ–º –∂—ë–ª—Ç—É—é –ø–æ–ª–æ—Å—É —Å —Ü–≤–µ—Ç–æ–º #f8bb42
        canvas.setFillColor(colors.HexColor('#f8bb42'))
        canvas.rect(0, height - header_height, width, header_height, stroke=0, fill=1)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ª–æ–≥–æ—Ç–∏–ø–∞
        logo_path = "logo.png"  
        logo_width = 2.5 * cm
        logo_height = 2.5 * cm
        logo_x = 1 * cm  # –æ—Ç—Å—Ç—É–ø –æ—Ç –ª–µ–≤–æ–≥–æ –∫—Ä–∞—è
        logo_y = height - header_height + (header_height - logo_height) / 2.0
        canvas.drawImage(logo_path, logo_x, logo_y,
                        width=logo_width, height=logo_height,
                        preserveAspectRatio=True, mask='auto')

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–µ–∫—Å—Ç–∞, —Ä–∞—Å–ø–æ–ª–∞–≥–∞–µ–º–æ–≥–æ —Ä—è–¥–æ–º —Å –ª–æ–≥–æ—Ç–∏–ø–æ–º
        text_lines = ["–ü–æ–º–æ–≥–∞–µ–º —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å", "—Ç–≤–æ–∏ —Ç–∞–ª–∞–Ω—Ç—ã"]
        text_font = "MPlusRounded1cB"
        text_size = 20
        text_color = colors.black
        text_x = logo_x + logo_width + 0.5 * cm  # –æ—Ç—Å—Ç—É–ø –æ—Ç –ª–æ–≥–æ—Ç–∏–ø–∞
        total_text_height = 2 * text_size + 2
        text_y = height - header_height + (header_height + total_text_height) / 2.0 - text_size

        canvas.setFont(text_font, text_size)
        canvas.setFillColor(text_color)
        for line in text_lines:
            canvas.drawString(text_x, text_y, line)
            text_y -= text_size + 2
        canvas.restoreState()


    # –°–±–æ—Ä —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    story = []


    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —ç–º–æ–¥–∑–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç–∏–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑–º–µ—Ä –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞)
    emoji_font_size = normal_style.fontSize  # –∑–¥–µ—Å—å 14, —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:
    resume = replace_with_emoji_pdf(resume, emoji_font_size)
    aggregated_text_prof = replace_with_emoji_pdf(aggregated_text_prof, emoji_font_size)
    prof_resume = replace_with_emoji_pdf(prof_resume, emoji_font_size)
    aggregated_text_personality = replace_with_emoji_pdf(aggregated_text_personality, emoji_font_size)
    aggregated_text_orientations = replace_with_emoji_pdf(aggregated_text_orientations, emoji_font_size)
    aggregated_text_talents = replace_with_emoji_pdf(aggregated_text_talents, emoji_font_size)
    talents_resume = replace_with_emoji_pdf(talents_resume, emoji_font_size)


    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    story.append(Paragraph("–ü–†–û–§–î–ò–ó–ê–ô–ù", title_style))
    story.append(DashedHRFlowable(doc.width, thickness=1))
    story.append(Spacer(1, 24))
    story.append(Paragraph(resume, normal_style))
    story.append(Spacer(1, 24))

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –±–ª–æ–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å —Ä–∞–º–∫–∞–º–∏
    add_block("–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç–∏", aggregated_text_prof + "<br/><br/>" + prof_resume, story)
    add_block("–õ–∏—á–Ω–æ—Å—Ç–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏", aggregated_text_personality, story)
    add_block("–¶–µ–Ω–Ω–æ—Å—Ç–Ω—ã–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã", aggregated_text_orientations, story)
    add_block("–°–∫—Ä—ã—Ç—ã–µ —Ç–∞–ª–∞–Ω—Ç—ã", aggregated_text_talents + "<br/><br/>" + talents_resume, story)

    # –°–æ–∑–¥–∞–Ω–∏–µ PDF-—Ñ–∞–π–ª–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–∞
    doc.build(story, onFirstPage=header, onLaterPages=header)
    return output_pdf_path, prof_resume, talents_resume, resume

PROMPTS_PATH = 'prompts.yaml'
PROMPTS_DEFAULT_PATH = 'prompts_default.yaml'

def load_prompts():
    with open(PROMPTS_PATH, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def save_prompts(prompts):
    with open(PROMPTS_PATH, 'w', encoding='utf-8') as f:
        yaml.safe_dump(prompts, f, allow_unicode=True)

def reset_prompts():
    with open(PROMPTS_DEFAULT_PATH, 'r', encoding='utf-8') as f:
        default_prompts = yaml.safe_load(f)
    save_prompts(default_prompts)
    return default_prompts

# --- parse_and_cache_pdf ---
def parse_and_cache_pdf(input_path):
    text = extract_text_from_pdf(input_path)
    text = clean_text(text)
    user_name = parse_user_info(text)
    tasks = {}
    for i in range(1, 9):
        task_text = extract_task(text, i)
        tasks[f"–ó–∞–¥–∞–Ω–∏–µ ‚Ññ{i}"] = task_text.strip()
    return {
        'user_name': user_name,
        'tasks': tasks,
        'task1_parsed': parse_task1(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ1", "")),
        'task2_parsed': parse_task2(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ2", "")),
        'task3_parsed': parse_task3(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ3", "")),
        'task4_parsed': parse_task4(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ4", "")),
        'task5_parsed': parse_task5(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ5", "")),
        'task6_parsed': parse_task6(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ6", "")),
        'task7_parsed': parse_task7(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ7", "")),
        'task8_parsed': parse_task8(tasks.get("–ó–∞–¥–∞–Ω–∏–µ ‚Ññ8", "")),
        'raw_text': text,
        'input_path': input_path
    }


# --- –ê–ì–†–ï–ì–ê–¶–ò–Ø –¢–ï–ö–°–¢–û–í –î–õ–Ø –†–ê–ó–î–ï–õ–û–í ---
def build_aggregated_prof_text(pdf_data):
    # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è –≤ process_pdf
    task1_parsed = pdf_data['task1_parsed']
    task3_parsed = pdf_data['task3_parsed']

    mappings = [
        ({"task1": "—Ä–∞–±–æ—Ç–µ —Å –ª—é–¥—å–º–∏", "task3": "—Å–æ—Ü–∏–∞–ª—å–Ω—ã–π"}, "–°–æ—Ü–∏–∞–ª—å–Ω—ã–π"),
        ({"task1": "—ç—Å—Ç–µ—Ç–∏—á–µ—Å–∫", "task3": "–∞—Ä—Ç–∏—Å—Ç–∏—á–Ω—ã–π"}, "–ê—Ä—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π"),
        ({"task1": "—Ä–∞–±–æ—Ç—ã —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π", "task3": "–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π"}, "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π"),
        ({"task1": "–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π", "task3": "–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π"}, "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π"),
        ({"task1": "—ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω"}, "–≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π"),
        ({"task1": "–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π", "task3": "–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π"}, "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π"),
        ({"task3": "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–Ω—ã–π"}, "–ò–Ω–∏—Ü–∏–∞—Ç–∏–≤–Ω—ã–π")
    ]
    def match(description, substr):
        return substr.lower() in description.lower()
    scores = {}
    for rule, type_name in mappings:
        total = 0
        if "task1" in rule and "task3" in rule:
            for t1 in task1_parsed:
                if match(t1["–æ–ø–∏—Å–∞–Ω–∏–µ"], rule["task1"]):
                    for t3 in task3_parsed:
                        if match(t3["–æ–ø–∏—Å–∞–Ω–∏–µ"], rule["task3"]):
                            total += t1["–±–∞–ª–ª—ã"] + t3["–±–∞–ª–ª—ã"]
        elif "task1" in rule:
            for t1 in task1_parsed:
                if match(t1["–æ–ø–∏—Å–∞–Ω–∏–µ"], rule["task1"]):
                    total += t1["–±–∞–ª–ª—ã"]
        elif "task3" in rule:
            for t3 in task3_parsed:
                if match(t3["–æ–ø–∏—Å–∞–Ω–∏–µ"], rule["task3"]):
                    total += t3["–±–∞–ª–ª—ã"]
        if total > 0:
            scores[type_name] = scores.get(type_name, 0) + total
    sorted_types = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    aggregated_text_prof = ""
    for type_name, score in sorted_types:
        aggregated_text_prof += f"<br/>üëâ <b>{type_name} —Ç–∏–ø –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:</b><br/>"
        if type_name in types_info:
            info = types_info[type_name]
            aggregated_text_prof += f"üìù {info['description']}<br/>"
            aggregated_text_prof += "üíº –ü–æ–¥—Ö–æ–¥—è—â–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏:<br/>"
            for prof in info["professions"]:
                aggregated_text_prof += f"   ‚úîÔ∏è {prof}<br/>"
    return aggregated_text_prof

def build_aggregated_talents_text(pdf_data):
    task8_parsed = pdf_data['task8_parsed']
    aggregated_text_talents = ""
    for talent in task8_parsed:
        info = hidden_talents_info.get(talent)
        if info:
            aggregated_text_talents += f"<br/>‚ú® {talent}:<br/>"
            aggregated_text_talents += f"üìù {info['description']}<br/><br/>"
            aggregated_text_talents += "üí° –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:<br/>"
            aggregated_text_talents += f"{info['examples']}<br/>"
        else:
            aggregated_text_talents += f"<br/><br/>‚ùó –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–∞–ª–∞–Ω—Ç—É ¬´{talent}¬ª –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.<br/><br/>"
    return aggregated_text_talents

def build_aggregated_personality_text(pdf_data):
    task2_parsed = pdf_data['task2_parsed']
    def extract_personality(code_str):
        start = code_str.find("(")
        end = code_str.find(")")
        if start != -1 and end != -1:
            return code_str[start+1:end].strip()
        return None
    personality_code = extract_personality(task2_parsed)
    aggregated_text_personality = ""
    if personality_code and personality_code in personality_info:
        info = personality_info[personality_code]
        aggregated_text_personality += f"<br/><br/>üé≠ –¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏: {info['name']}<br/>"
        aggregated_text_personality += f"üìù {info['description']}<br/><br/>"
        aggregated_text_personality += "üöÄ –î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º, —á—Ç–æ –¥–µ–ª–∞–µ—Ç —Ç–µ–±—è —Ç–∞–∫–∏–º –æ—Å–æ–±–µ–Ω–Ω—ã–º:<br/><br/>"
        for feature in info["features"]:
            aggregated_text_personality += f"üîë {feature['feature']}:<br/>"
            aggregated_text_personality += f"üìù {feature['description']}<br/>"
            aggregated_text_personality += f"üí° {feature['examples']}<br/><br/>"
    else:
        aggregated_text_personality = task2_parsed
    return aggregated_text_personality

def build_aggregated_orientations_text(pdf_data):
    task4_parsed = pdf_data['task4_parsed']
    def build_orientations_text(task_results, orientations):
        aggregated_text_orientations = "–¢–≤–æ–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–Ω—ã–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã –ø–æ–º–æ–≥–∞—é—Ç —Ç–µ–±–µ –ø–æ–Ω—è—Ç—å, —á—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è —Ç–µ–±—è –≤ –∂–∏–∑–Ω–∏ –∏ –∫–∞—Ä—å–µ—Ä–µ. –†–µ–∞–ª–∏–∑—É—è –∏—Ö, —Ç—ã –º–æ–∂–µ—à—å —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å —Å–µ–±—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É—Å–ø–µ—à–Ω—ã–º –∏ –≥–∞—Ä–º–æ–Ω–∏—á–Ω—ã–º –≤ —Å–≤–æ–µ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏. <br/> –î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º, —á—Ç–æ –∑–Ω–∞—á–∏—Ç –∫–∞–∂–¥–∞—è –∏–∑ –Ω–∏—Ö –∏ –∫–∞–∫ –æ–Ω–∏ –º–æ–≥—É—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å—Å—è:"
        for result in task_results:
            desc = result['–æ–ø–∏—Å–∞–Ω–∏–µ']
            data = orientations.get(desc)
            if data:
                aggregated_text_orientations += (
                    f"<br/>üí°{data['–æ—Ä–∏–µ–Ω—Ç–∏—Ä']}<br/>"
                    f"üìù{data['–æ–ø–∏—Å–∞–Ω–∏–µ']}<br/>"
                    "‚úîÔ∏è –ö–∞–∫–æ–π –ø—É—Ç—å —Ç–µ–±–µ –ø–æ–¥–æ–π–¥–µ—Ç?<br/>"
                    f"{data['–ø—É—Ç—å']}<br/>"
                )
            else:
                aggregated_text_orientations += f"<br/><br/>‚ùó –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è: {desc}<br/>"
        return aggregated_text_orientations
    return build_orientations_text(task4_parsed, orientations)


# --- create_pdf ---
def create_pdf(output_path, pdf_data, prof_resume, talents_resume, final_resume):
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Flowable
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import cm
    from reportlab.lib import colors
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    import os
    base_dir = os.path.dirname(os.path.abspath(__file__))
    mulish_regular_path = os.path.join(base_dir, 'Mulish-Regular.ttf')
    mplus_bold_path = os.path.join(base_dir, 'MPLUSRounded1c-ExtraBold.ttf')
    if not os.path.exists(mulish_regular_path):
        raise FileNotFoundError(f"–§–∞–π–ª —à—Ä–∏—Ñ—Ç–∞ '{mulish_regular_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    if not os.path.exists(mplus_bold_path):
        raise FileNotFoundError(f"–§–∞–π–ª —à—Ä–∏—Ñ—Ç–∞ '{mplus_bold_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    pdfmetrics.registerFont(TTFont('Mulish-Regular', mulish_regular_path))
    pdfmetrics.registerFont(TTFont('MPlusRounded1cB', mplus_bold_path))
    styles = getSampleStyleSheet()
    styles['Normal'].fontName = 'Mulish-Regular'
    styles['Normal'].fontSize = 14
    styles['Normal'].leading = 16
    styles['Heading2'].fontName = "MPlusRounded1cB"
    styles['Heading2'].fontSize = 16
    styles['Heading2'].leading = 20
    title_style = ParagraphStyle(
        'Title', parent=styles['Heading2'], fontSize=28, alignment=1, spaceAfter=16,
    )
    block_header_style = ParagraphStyle(
        'BlockHeader', parent=styles['Heading2'], fontSize=18, spaceAfter=8,
    )
    normal_style = styles['Normal']
    class RoundedBorderedParagraph(Flowable):
        def __init__(self, text, style, padding=0.5*cm, radius=10, dash=(3, 3)):
            Flowable.__init__(self)
            self.text = text
            self.style = style
            self.padding = padding
            self.radius = radius
            self.dash = dash
            self.paragraph = Paragraph(text, style)
            self.width = 0
            self.height = 0
        def wrap(self, availWidth, availHeight):
            available_text_width = availWidth - 2 * self.padding
            w, h = self.paragraph.wrap(available_text_width, availHeight - 2 * self.padding)
            self.width = w + 2 * self.padding
            self.height = h + 2 * self.padding
            return self.width, self.height
        def draw(self):
            self.canv.saveState()
            self.canv.setStrokeColor(colors.HexColor('#f8bb42'))
            self.canv.setLineWidth(1)
            self.canv.setDash(self.dash[0], self.dash[1])
            self.canv.roundRect(0, 0, self.width, self.height, self.radius, stroke=1, fill=0)
            self.canv.restoreState()
            self.paragraph.drawOn(self.canv, self.padding, self.padding)
        def split(self, availWidth, availHeight):
            available_text_width = availWidth - 2 * self.padding
            available_text_height = availHeight - 2 * self.padding
            split_paragraphs = self.paragraph.split(available_text_width, available_text_height)
            if not split_paragraphs:
                return []
            flowables = []
            for p in split_paragraphs:
                new_flowable = RoundedBorderedParagraph("", self.style, self.padding, self.radius, self.dash)
                new_flowable.paragraph = p
                w, h = p.wrap(available_text_width, available_text_height)
                new_flowable.width = w + 2 * self.padding
                new_flowable.height = h + 2 * self.padding
                flowables.append(new_flowable)
            return flowables
    class DashedHRFlowable(Flowable):
        def __init__(self, width, thickness=1):
            Flowable.__init__(self)
            self.width = width
            self.thickness = thickness
        def wrap(self, availWidth, availHeight):
            return self.width, self.thickness
        def draw(self):
            self.canv.saveState()
            self.canv.setStrokeColor(colors.HexColor('#f8bb42'))
            self.canv.setLineWidth(self.thickness)
            self.canv.setDash(3, 3)
            self.canv.line(0, self.thickness/2.0, self.width, self.thickness/2.0)
            self.canv.restoreState()
    def add_block(title, text_content, story):
        story.append(Paragraph(title, block_header_style))
        story.append(Spacer(1, 14))
        bordered_paragraph = RoundedBorderedParagraph(text_content, normal_style)
        story.append(bordered_paragraph)
        story.append(Spacer(1, 24))
    def header(canvas, doc):
        width, height = A4
        header_height = 3 * cm
        canvas.saveState()
        canvas.setFillColor(colors.HexColor('#f8bb42'))
        canvas.rect(0, height - header_height, width, header_height, stroke=0, fill=1)
        logo_path = os.path.join(base_dir, "logo.png")
        logo_width = 2.5 * cm
        logo_height = 2.5 * cm
        logo_x = 1 * cm
        logo_y = height - header_height + (header_height - logo_height) / 2.0
        try:
            canvas.drawImage(logo_path, logo_x, logo_y, width=logo_width, height=logo_height, preserveAspectRatio=True, mask='auto')
        except Exception:
            pass
        text_lines = ["–ü–æ–º–æ–≥–∞–µ–º —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å", "—Ç–≤–æ–∏ —Ç–∞–ª–∞–Ω—Ç—ã"]
        text_font = "MPlusRounded1cB"
        text_size = 20
        text_color = colors.black
        text_x = logo_x + logo_width + 0.5 * cm
        total_text_height = 2 * text_size + 2
        text_y = height - header_height + (header_height + total_text_height) / 2.0 - text_size
        try:
            canvas.setFont(text_font, text_size)
        except Exception:
            canvas.setFont("Helvetica-Bold", text_size)
        canvas.setFillColor(text_color)
        for line in text_lines:
            canvas.drawString(text_x, text_y, line)
            text_y -= text_size + 2
        canvas.restoreState()
    emoji_font_size = normal_style.fontSize
    def safe(text):
        return text if text else ""
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞—Ä–∞–Ω–µ–µ (—É—Å–∫–æ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏)
    resume = replace_with_emoji_pdf(final_resume, emoji_font_size)
    aggregated_text_prof = replace_with_emoji_pdf(build_aggregated_prof_text(pdf_data), emoji_font_size)
    prof_resume = replace_with_emoji_pdf(prof_resume, emoji_font_size)
    aggregated_text_personality = replace_with_emoji_pdf(build_aggregated_personality_text(pdf_data), emoji_font_size)
    aggregated_text_orientations = replace_with_emoji_pdf(build_aggregated_orientations_text(pdf_data), emoji_font_size)
    aggregated_text_talents = replace_with_emoji_pdf(build_aggregated_talents_text(pdf_data), emoji_font_size)
    talents_resume = replace_with_emoji_pdf(talents_resume, emoji_font_size)
    story = []
    story.append(Paragraph("–ü–†–û–§–î–ò–ó–ê–ô–ù", title_style))
    story.append(DashedHRFlowable(A4[0] - 80, thickness=1))
    story.append(Spacer(1, 24))
    # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ –≤ –Ω–∞—á–∞–ª–µ, –∫–∞–∫ –≤ —ç—Ç–∞–ª–æ–Ω–µ
    story.append(Paragraph(resume, normal_style))
    story.append(Spacer(1, 24))
    add_block("–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç–∏", aggregated_text_prof + "<br/><br/>" + prof_resume, story)
    add_block("–õ–∏—á–Ω–æ—Å—Ç–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏", aggregated_text_personality, story)
    add_block("–¶–µ–Ω–Ω–æ—Å—Ç–Ω—ã–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã", aggregated_text_orientations, story)
    add_block("–°–∫—Ä—ã—Ç—ã–µ —Ç–∞–ª–∞–Ω—Ç—ã", aggregated_text_talents + "<br/><br/>" + talents_resume, story)
    doc = SimpleDocTemplate(output_path, pagesize=A4, rightMargin=40, leftMargin=40, topMargin=3*cm + 40, bottomMargin=40)
    doc.build(story, onFirstPage=header, onLaterPages=header)
    return output_path

def get_pdf_output_path(user_name):
    downloads_dir = Path(os.getcwd()) / "downloads"
    # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ / –∏ \, –ø—Ä–æ–±–µ–ª—ã –æ—Å—Ç–∞–≤–ª—è–µ–º
    safe_name = str(user_name).replace('/', '_').replace('\\', '_')
    return str(downloads_dir / f"–î–æ—Å—å–µ {safe_name}.pdf")
